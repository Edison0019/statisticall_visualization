{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from io import StringIO\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "from pprint import pprint\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Permutations giving a starting point'''\n",
    "portnames = [\"PAN\", \"AMS\", \"CAS\", \"NYC\", \"HEL\"]\n",
    " \n",
    "def permutations(route, ports):\n",
    "    if len(ports) == 0:\n",
    "        print(' '.join(portnames[x] for x in route))\n",
    "    else:\n",
    "        for p in range(len(ports)):\n",
    "            permutations(route + [ports[p]],ports[:p]+ports[p+1:])\n",
    "\n",
    "# this will start the recursion with 0 as the first stop\n",
    "permutations([0], list(range(1, len(portnames))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Distance calculation using brute force approaches'''\n",
    "portnames = [\"PAN\", \"AMS\", \"CAS\", \"NYC\", \"HEL\"]\n",
    "\n",
    "# https://sea-distances.org/\n",
    "# nautical miles converted to km\n",
    "\n",
    "D = [\n",
    "        [0,8943,8019,3652,10545],\n",
    "        [8943,0,2619,6317,2078],\n",
    "        [8019,2619,0,5836,4939],\n",
    "        [3652,6317,5836,0,7825],\n",
    "        [10545,2078,4939,7825,0]\n",
    "    ]\n",
    "\n",
    "# https://timeforchange.org/co2-emissions-shipping-goods\n",
    "# assume 20g per km per metric ton (of pineapples)\n",
    "\n",
    "co2 = 0.020\n",
    "\n",
    "# DATA BLOCK ENDS\n",
    "\n",
    "# these variables are initialised to nonsensical values\n",
    "# your program should determine the correct values for them\n",
    "smallest = 1000000\n",
    "bestroute = [0, 0, 0, 0, 0]\n",
    "\n",
    "def permutations(route, ports):\n",
    "    global smallest, bestroute\n",
    "    if len(ports) <= 0:\n",
    "        distances = []\n",
    "        for i,v in enumerate(route):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            else:\n",
    "                distances.append(D[route[i-1]][v])\n",
    "        total_emission = sum(distances) * co2\n",
    "        if total_emission < smallest:\n",
    "            smallest = total_emission\n",
    "            bestroute = route\n",
    "    for v in range(len(ports)):\n",
    "        permutations(route + [ports[v]],ports[:v] + ports[v+1:])\n",
    "\n",
    "def main():\n",
    "    # this will start the recursion \n",
    "    permutations([0], list(range(1, len(portnames))))\n",
    "\n",
    "    # print the best route and its emissions\n",
    "    print(' '.join([portnames[i] for i in bestroute]) + \" %.1f kg\" % smallest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Hill climbing'''                              \t \n",
    "# generate random mountains                                                                               \t \n",
    "\n",
    "w = [.05, random.random()/3, random.random()/3]\n",
    "h = [1.+math.sin(1+x/.6)*w[0]+math.sin(-.3+x/9.)*w[1]+math.sin(-.2+x/30.)*w[2] for x in range(100)]\n",
    "\n",
    "def climb(x, h):\n",
    "    # keep climbing until we've found a summit\n",
    "    summit = False\n",
    "\n",
    "    # edit here\n",
    "    while not summit:\n",
    "        summit = True         # stop unless there's a way up\n",
    "        for i in range(1,6):\n",
    "            if h[x + i] > h[x]: #go right\n",
    "                x = x + i\n",
    "                summit = False \n",
    "        for i in range(1,6):\n",
    "            if h[x - i] > h[x]: #go left\n",
    "                x = x - i\n",
    "                summit = False  \n",
    "\n",
    "        # if h[x + 1] > h[x]:\n",
    "        #     x = x + 1         # right is higher, go there\n",
    "        #     summit = False    # and keep going\n",
    "    return x\n",
    "\n",
    "\n",
    "def main(h):\n",
    "    # start at a random place                                                                                  \t \n",
    "    x0 = random.randint(1, 98)\n",
    "    x = climb(x0, h)\n",
    "\n",
    "    return x0, x\n",
    "\n",
    "v = main(h)\n",
    "\n",
    "plt.plot(np.arange(100),h,v[0],h[v[0]],\"s\",v[1],h[v[1]],\"^\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accept_prob(S_old, S_new, T):\n",
    "    # this is the acceptance \"probability\" in the greedy hill-climbing method\n",
    "    # where new solutions are accepted if and only if they are better\n",
    "    # than the old one.\n",
    "    # change it to be the acceptance probability in simulated annealing\n",
    "    if S_new > S_old:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.exp(-(S_old - S_new) / T)\n",
    "\n",
    "\n",
    "# the above function will be used as follows. this is shown just for\n",
    "# your information; you don't have to change anything here\n",
    "def accept(S_old, S_new, T):\n",
    "    if random.random() < accept_prob(S_old, S_new, T):\n",
    "        print(True)\n",
    "    else:\n",
    "        print(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Simulated annealing implementation'''\n",
    "N = 100     # size of the problem is N x N                                      \n",
    "steps = 3000    # total number of iterations                                        \n",
    "tracks = 50\n",
    "\n",
    "# generate a landscape with multiple local optima                                          \n",
    "def generator(x, y, x0=0.0, y0=0.0):\n",
    "    return np.sin((x/N-x0)*np.pi)+np.sin((y/N-y0)*np.pi)+\\\n",
    "        .07*np.cos(12*(x/N-x0)*np.pi)+.07*np.cos(12*(y/N-y0)*np.pi)\n",
    "\n",
    "x0 = np.random.random() - 0.5\n",
    "y0 = np.random.random() - 0.5\n",
    "h = np.fromfunction(np.vectorize(generator), (N, N), x0=x0, y0=y0, dtype=int)\n",
    "peak_x, peak_y = np.unravel_index(np.argmax(h), h.shape)\n",
    "\n",
    "# starting points                                                               \n",
    "x = np.random.randint(0, N, tracks)\n",
    "y = np.random.randint(0, N, tracks)\n",
    "\n",
    "def main():\n",
    "    global x\n",
    "    global y\n",
    "\n",
    "    for step in range(steps):\n",
    "        # add a temperature schedule here\n",
    "        T = max(.0001, ((steps - step)/steps)**3-.005)\n",
    "        # update solutions on each search track                                     \n",
    "        for i in range(tracks):\n",
    "            # try a new solution near the current one                               \n",
    "            x_new = np.random.randint(max(0, x[i]-2), min(N, x[i]+2+1))\n",
    "            y_new = np.random.randint(max(0, y[i]-2), min(N, y[i]+2+1))\n",
    "            S_old = h[x[i], y[i]]\n",
    "            S_new = h[x_new, y_new]\n",
    "\n",
    "            # change this to use simulated annealing\n",
    "            if S_new > S_old:\n",
    "                x[i], y[i] = x_new, y_new   # new solution is better, go there       \n",
    "            else:\n",
    "                if random.random() < np.exp(-(S_old - S_new) / T):\n",
    "                    x[i], y[i] = x_new, y_new\n",
    "\n",
    "    # Number of tracks found the peak\n",
    "    print(sum([x[j] == peak_x and y[j] == peak_y for j in range(tracks)])) \n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(p1,size=10000):\n",
    "    # change this so that it generates 10000 random zeros and ones\n",
    "    # where the probability of one is p1\n",
    "    seq = np.random.choice([0,1], p=[1-p1, p1], size=size)\n",
    "    return seq\n",
    "\n",
    "def count(seq):\n",
    "    counter, flag = 0, 1\n",
    "    for i in seq:\n",
    "        if i == 1:\n",
    "            if flag >= 5:\n",
    "                counter += 1\n",
    "            else:\n",
    "                flag += 1\n",
    "        else:\n",
    "            flag = 1\n",
    "    return counter\n",
    "\n",
    "def main(p1):\n",
    "    seq = generate(p1)\n",
    "    return count(seq)\n",
    "\n",
    "print(main(2/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''probability of choosing a fisher given a sex'''\n",
    "countries = ['Denmark', 'Finland', 'Iceland', 'Norway', 'Sweden']\n",
    "populations = [5615000, 5439000, 324000, 5080000, 9609000]\n",
    "male_fishers = [1822, 2575, 3400, 11291, 1731]\n",
    "female_fishers = [69, 77, 400, 320, 26] \n",
    "\n",
    "def guess(winner_gender):\n",
    "    if winner_gender == 'female':\n",
    "        fishers = female_fishers\n",
    "    else:\n",
    "        fishers = male_fishers\n",
    "    # the index of the highest fishing country\n",
    "    i = fishers.index(max(fishers))\n",
    "    guess, biggest = countries[i], fishers[i] / sum(fishers)\n",
    "    return (guess, biggest * 100)  \n",
    "\n",
    "def main():\n",
    "    country, fraction = guess(\"male\")\n",
    "    print(\"if the winner is male, my guess is he's from %s; probability %.2f%%\" % (country, fraction))\n",
    "    country, fraction = guess(\"female\")\n",
    "    print(\"if the winner is female, my guess is she's from %s; probability %.2f%%\" % (country, fraction))\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''the bayes rule applied'''\n",
    "def bot8(pbot, p8_bot, p8_human):\n",
    "    #the probability of a username\n",
    "    #with 8 digits\n",
    "    d_8 = p8_bot * pbot + p8_human * (1-pbot)\n",
    "    #the probability of being a bot\n",
    "    #when the username has 8 digits\n",
    "    '''P(A|B) = [P(B|A) * P(A)]/P(B)'''\n",
    "    pbot_8 = (p8_bot * pbot) / d_8\n",
    "    print(pbot_8)\n",
    "\n",
    "# you can change these values to test your program with different values\n",
    "pbot = 0.1\n",
    "p8_bot = 0.8\n",
    "p8_human = 0.05\n",
    "\n",
    "bot8(pbot, p8_bot, p8_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''rolling a dice and determining the roll using bayes rule'''\n",
    "p1 = [1/6, 1/6, 1/6, 1/6, 1/6, 1/6]   # normal\n",
    "p2 = [0.1, 0.1, 0.1, 0.1, 0.1, 0.5]   # loaded\n",
    "\n",
    "def roll(loaded):\n",
    "    if loaded:\n",
    "        print(\"rolling a loaded die\")\n",
    "        p = p2\n",
    "    else:\n",
    "        print(\"rolling a normal die\")\n",
    "        p = p1\n",
    "\n",
    "    # roll the dice 10 times\n",
    "    # add 1 to get dice rolls from 1 to 6 instead of 0 to 5\n",
    "    sequence = np.random.choice(6, size=10, p=p) + 1 \n",
    "    for roll in sequence:\n",
    "        print(\"rolled %d\" % roll)\n",
    "        \n",
    "    return sequence\n",
    "\n",
    "def bayes(sequence):\n",
    "    odds = 1.0           # start with odds 1:1\n",
    "    for roll in sequence:\n",
    "        odds *= p2[roll-1] / p1[roll-1]             # edit here to update the odds\n",
    "    if odds > 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "sequence = roll(True)\n",
    "if bayes(sequence):\n",
    "    print(\"I think loaded\")\n",
    "else:\n",
    "    print(\"I think normal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''using linear regression for predicting the price of multiple cottages'''\n",
    "X = [[66, 5, 15, 2, 500], \n",
    "     [21, 3, 50, 1, 100], \n",
    "     [120, 15, 5, 2, 1200]]\n",
    "c = [3000, 200, -50, 5000, 100]    # coefficient values\n",
    "\n",
    "def predict(X, c):\n",
    "    for e in range(len(X)):\n",
    "        price = 0\n",
    "        for i in range(len(X[e])):\n",
    "            price += X[e][i] * c[i]          \n",
    "        print(price)\n",
    "\n",
    "predict(X, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best set is set 1\n"
     ]
    }
   ],
   "source": [
    "'''Calculating error for deciding the best set of coefficients'''\n",
    "# data\n",
    "X = np.array([[66, 5, 15, 2, 500], \n",
    "              [21, 3, 50, 1, 100], \n",
    "              [120, 15, 5, 2, 1200]])\n",
    "y = np.array([250000, 60000, 525000])\n",
    "\n",
    "# alternative sets of coefficient values\n",
    "c = np.array([[3000, 200 , -50, 5000, 100], \n",
    "              [2000, -250, -100, 150, 250], \n",
    "              [3000, -100, -150, 0, 150]])   \n",
    "\n",
    "def find_best(X, y, c):\n",
    "    smallest_error = np.Inf\n",
    "    best_index = -1\n",
    "    index = 0\n",
    "    for coeff in c:\n",
    "        container = []\n",
    "        for cabin in X:\n",
    "            accumulated = 0\n",
    "            for i in range(len(cabin)):\n",
    "                accumulated += cabin[i] * coeff[i]\n",
    "            container.append(accumulated)\n",
    "        #error\n",
    "        error = ((y - np.array(container)) ** 2).sum()\n",
    "        if error < smallest_error:\n",
    "            smallest_error = error\n",
    "            best_index = index\n",
    "        index += 1\n",
    "    print(\"the best set is set %d\" % best_index)\n",
    "\n",
    "\n",
    "find_best(X, y, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2989.6  800.6  -44.8 3890.8   99.8]\n",
      "[127907.6 222269.8 143604.5 268017.6 460686.6 406959.9]\n"
     ]
    }
   ],
   "source": [
    "'''linear regression on a matrix of values'''\n",
    "\n",
    "input_string = '''\n",
    "25 2 50 1 500 127900\n",
    "39 3 10 1 1000 222100\n",
    "13 2 13 1 1000 143750\n",
    "82 5 20 2 120 268000\n",
    "130 6 10 2 600 460700\n",
    "115 6 10 1 550 407000\n",
    "'''\n",
    "\n",
    "np.set_printoptions(precision=1)    # this just changes the output settings for easier reading\n",
    " \n",
    "def fit_model(input_file):\n",
    "    matrix = np.genfromtxt(input_file)\n",
    "    c = np.linalg.lstsq(matrix[:,:5],matrix[:,5],rcond=None)[0]\n",
    "    x = matrix[:,:5]\n",
    "\n",
    "    print(c)\n",
    "    print(x @ c)\n",
    "\n",
    "# simulate reading a file\n",
    "input_file = StringIO(input_string)\n",
    "fit_model(input_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2989.6  800.6  -44.8 3890.8   99.8]\n",
      "[198102.4 289108.3]\n"
     ]
    }
   ],
   "source": [
    "'''using linear regression in numpy using train and test data'''\n",
    "train_string = '''\n",
    "25 2 50 1 500 127900\n",
    "39 3 10 1 1000 222100\n",
    "13 2 13 1 1000 143750\n",
    "82 5 20 2 120 268000\n",
    "130 6 10 2 600 460700\n",
    "115 6 10 1 550 407000\n",
    "'''\n",
    "\n",
    "test_string = '''\n",
    "36 3 15 1 850 196000\n",
    "75 5 18 2 540 290000\n",
    "'''\n",
    "\n",
    "def main():\n",
    "    np.set_printoptions(precision=1)    # this just changes the output settings for easier reading\n",
    "    train = np.genfromtxt(StringIO(train_string))\n",
    "    # read in the training data and separate it to x_train and y_train\n",
    "    x_train,y_train = train[:,:5],train[:,5]\n",
    "    # fit a linear regression model to the data and get the coefficients\n",
    "    c = np.linalg.lstsq(x_train,y_train,rcond=None)[0]\n",
    "\n",
    "    # read in the test data and separate x_test from it\n",
    "    test = np.genfromtxt(StringIO(test_string))\n",
    "    x_test = test[:,:5]\n",
    "\n",
    "    # print out the linear regression coefficients\n",
    "    print(c)\n",
    "\n",
    "    # this will print out the predicted prics for the two new cabins in the test data set\n",
    "    print(x_test @ c)\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "'''nearest neighbor using Euclidean distance between two points'''\n",
    "x_train = np.random.rand(10, 3)   # generate 10 random vectors of dimension 3\n",
    "x_test = np.random.rand(3)        # generate one more random vector of the same dimension\n",
    "\n",
    "def dist(a, b):\n",
    "    sum = 0\n",
    "    for ai, bi in zip(a, b):\n",
    "        sum = sum + (ai - bi)**2\n",
    "    return np.sqrt(sum)\n",
    "    \n",
    "def nearest(x_train, x_test):\n",
    "    nearest = -1\n",
    "    min_distance = np.Inf\n",
    "    distance = 0\n",
    "    for i,v in enumerate(x_train):\n",
    "        distance = dist(v,x_test)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            nearest = i\n",
    "    print(nearest)\n",
    "\n",
    "nearest(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "# create random data with two classes\n",
    "X, Y = make_blobs(n_samples=16, n_features=2, centers=2, center_box=(-2, 2))\n",
    "\n",
    "# scale the data so that all values are between 0.0 and 1.0\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "# split two data points from the data as test data and\n",
    "# use the remaining n-2 points as the training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=2)\n",
    "\n",
    "# place-holder for the predicted classes\n",
    "y_predict = np.empty(len(y_test), dtype=np.int64)\n",
    "\n",
    "# produce line segments that connect the test data points\n",
    "# to the nearest neighbors for drawing the chart\n",
    "lines = []\n",
    "\n",
    "# distance function\n",
    "def dist(a, b):\n",
    "    sum = 0\n",
    "    for ai, bi in zip(a, b):\n",
    "        sum = sum + (ai - bi)**2\n",
    "    return np.sqrt(sum)\n",
    "\n",
    "\n",
    "def main(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    global y_predict\n",
    "    global lines\n",
    "\n",
    "    k = 3    # classify our test items based on the classes of 3 nearest neighbors\n",
    "\n",
    "    # process each of the test data points\n",
    "    for i, test_item in enumerate(X_test):\n",
    "        # calculate the distances to all training points\n",
    "        distances = [dist(train_item, test_item) for train_item in X_train]\n",
    "\n",
    "        # `c` a container for quantities\n",
    "        c = [np.Inf for i in range(k)]\n",
    "        nearest = [0 for _ in range(k)]\n",
    "        # this part will generate an ordered list\n",
    "        # of k elements sorted ascending\n",
    "        for _ in range(len(c)):\n",
    "            for p,v in enumerate(distances):\n",
    "                if _ == 0:\n",
    "                    if v < c[_]:\n",
    "                        c[_] = v\n",
    "                        nearest[_] = p\n",
    "                elif v < c[_] and c[_ - 1] < v:\n",
    "                        c[_] = v\n",
    "                        nearest[_] = p\n",
    "        \n",
    "\n",
    "        # create a line connecting the points for the chart\n",
    "        for elm in nearest:\n",
    "            lines.append(np.stack((test_item, X_train[elm])))\n",
    "\n",
    "        # this dict will hold the count of ones/zeros as element:count pairs\n",
    "        d = {x:[y_train[i] for i in nearest].count(x) for x in (1,0)}\n",
    "        y_predict[i] = max(d,key=lambda x: d[x])\n",
    "    \n",
    "    print(y_predict)\n",
    "main(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "'''using Manhattan distance to get the difference of a bag of words'''\n",
    "import numpy as np\n",
    "\n",
    "data = [[1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
    "        [1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1],\n",
    "        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1],\n",
    "        [1, 1, 1, 0, 1, 3, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1]]\n",
    "\n",
    "def find_nearest_pair(data):\n",
    "    N = len(data)\n",
    "    dist = np.empty((N, N), dtype=np.float)\n",
    "    # outer loop\n",
    "    for ind,val in enumerate(data):\n",
    "        # inner loop for commparing indices\n",
    "        for ind1,val1 in enumerate(data):\n",
    "            # Inf if equal indices\n",
    "            if ind == ind1:\n",
    "                dist[ind,ind1] = np.Inf\n",
    "            else:\n",
    "                # get the manhattan distance\n",
    "                manh_dist = 0\n",
    "                for l0,l1 in zip(val,val1):\n",
    "                    manh_dist += np.abs(l0 - l1)\n",
    "                dist[ind,ind1] = manh_dist\n",
    "    print(np.unravel_index(np.argmin(dist), dist.shape))\n",
    "\n",
    "find_nearest_pair(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)\n"
     ]
    }
   ],
   "source": [
    "text = '''Humpty Dumpty sat on a wall\n",
    "Humpty Dumpty had a great fall\n",
    "all the king's horses and all the king's men\n",
    "couldn't put Humpty together again'''\n",
    "import re\n",
    "def main(text):\n",
    "    # first part - creating needed variables/data\n",
    "    lower_words = text.lower().replace('\\n',' ').split(' ')\n",
    "    docs = [[i.lower() for i in line.split()] for line in text.split('\\n')]\n",
    "    unique_words = []\n",
    "    for word in lower_words:\n",
    "        if not word in unique_words:\n",
    "            unique_words.append(word)\n",
    "    \n",
    "    # < DATA >\n",
    "    line_dist = np.zeros((len(docs),len(docs))) # list of distances of length docs*docs\n",
    "    vector = np.zeros((len(docs),len(unique_words))) # a list of vectors length docs*unique_words\n",
    "    \n",
    "    # second part - term frequency/document frequency\n",
    "\n",
    "    metrics = []\n",
    "    for line in docs:\n",
    "        elements = {}\n",
    "        \n",
    "        for word in line:\n",
    "            if not word in elements:\n",
    "                elements[word] = {\n",
    "                    'tf':1 / line.count(word),\n",
    "                    'df':1 / sum([1 for x in docs if word in x])\n",
    "                }\n",
    "        metrics.append(elements)\n",
    "        del elements\n",
    "    \n",
    "    # third part - determine tf-idf in a 2-D vector\n",
    "    \n",
    "    for r,v in enumerate(vector):\n",
    "        for c,v1 in enumerate(unique_words):\n",
    "            if v1 in metrics[r]:\n",
    "                vector[r,c] = metrics[r][v1]['tf'] * np.log10(1 / metrics[r][v1]['df'])\n",
    "   \n",
    "    # fourth part - determine the distance of all the lines (docs)\n",
    "\n",
    "    for ind,val in enumerate(vector):\n",
    "        # inner loop for commparing indices\n",
    "        for ind1,val1 in enumerate(vector):\n",
    "            # np.Inf if equal indices\n",
    "            if ind == ind1:\n",
    "                line_dist[ind,ind1] = np.Inf\n",
    "            else:\n",
    "                # get the eulean distance\n",
    "                manh_dist = 0\n",
    "                for l0,l1 in zip(val,val1):\n",
    "                    manh_dist += (l0 - l1) ** 2\n",
    "                line_dist[ind,ind1] = np.sqrt(manh_dist)\n",
    "    print(np.unravel_index(np.argmin(line_dist), line_dist.shape))\n",
    "\n",
    "main(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1 0.1544652650835347\n",
      "c2 0.45016600268752216\n",
      "c3 0.8455347349164652\n"
     ]
    }
   ],
   "source": [
    "'''sigmoid function'''\n",
    "\n",
    "x = np.array([4, 3, 0])\n",
    "c1 = np.array([-.5, .1, .08])\n",
    "c2 = np.array([-.2, .2, .31])\n",
    "c3 = np.array([.5, -.1, 2.53])\n",
    "\n",
    "def distance(a,b):\n",
    "    value = 0\n",
    "    for x,y in zip(a,b):\n",
    "        value += x*y\n",
    "    return value\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+math.exp(-z))\n",
    "    # print(0)\n",
    "\n",
    "def main():\n",
    "    print('c1',sigmoid(distance(x,c1)))\n",
    "    print('c2',sigmoid(distance(x,c2)))\n",
    "    print('c3',sigmoid(distance(x,c3)))\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
